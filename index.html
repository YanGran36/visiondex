<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <title>VisionDex - Espejo M√°gico</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      background: black;
      height: 100vh;
      overflow: hidden;
      display: flex;
      align-items: center;
      justify-content: center;
      flex-direction: column;
      color: white;
      font-family: Arial, sans-serif;
    }

    #avatar {
      width: 320px;
      height: 320px;
      border-radius: 50%;
      object-fit: cover;
      border: 10px solid transparent;
      box-shadow: 0 0 80px rgba(255,255,255,0.05);
      transition: border-color 2s ease, box-shadow 2s ease;
    }

    button {
      margin-top: 30px;
      padding: 14px 30px;
      font-size: 18px;
      background: #111;
      color: white;
      border: 2px solid #444;
      border-radius: 8px;
      cursor: pointer;
    }

    #response {
      margin-top: 20px;
      text-align: center;
      white-space: pre-line;
      max-width: 90vw;
    }
  </style>
</head>
<body>
  <img id="avatar" src="https://chatgpt-image-hosting.s3.amazonaws.com/mirror_face_visiondex.png" alt="VisionDex Avatar" />
  <div id="response">Presiona el bot√≥n para hablar con VisionDex</div>
  <button id="talkBtn">üéôÔ∏è Hablar</button>

  <script>
    const OPENAI_KEY = "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";
    const ELEVEN_API_KEY = "sk_94f3b84a958dbfd99972c79e0bd6c2fa4f71f9b8bf83d5e5";
    const VOICE_ID = "8DzKSPdgEQPaK5vKG0Rs";
    
    const responseBox = document.getElementById("response");
    const avatar = document.getElementById("avatar");
    const talkBtn = document.getElementById("talkBtn");

    const colors = ["#4ecdc4", "#c7f464", "#ff6b6b", "#ffcc5c", "#9d50bb", "#00f2fe"];
    let colorIndex = 0;
    setInterval(() => {
      avatar.style.borderColor = colors[colorIndex];
      avatar.style.boxShadow = `0 0 60px ${colors[colorIndex]}`;
      colorIndex = (colorIndex + 1) % colors.length;
    }, 12000);

    async function getGPTReply(text) {
      const res = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${OPENAI_KEY}`,
        },
        body: JSON.stringify({
          model: "gpt-3.5-turbo",
          messages: [
            { role: "system", content: "Eres VisionDex, un gu√≠a personal sabio, claro y con voz calmada." },
            { role: "user", content: text }
          ]
        }),
      });
      const data = await res.json();
      return data.choices[0].message.content;
    }

    async function speakWithElevenLabs(text) {
      try {
        const res = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "xi-api-key": ELEVEN_API_KEY,
          },
          body: JSON.stringify({
            text: text,
            model_id: "eleven_monolingual_v1",
            voice_settings: { stability: 0.5, similarity_boost: 0.7 }
          }),
        });
        const audioBlob = await res.blob();
        const audioURL = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioURL);
        audio.play();
      } catch (error) {
        responseBox.textContent += "\n‚ö†Ô∏è Error al reproducir audio.";
      }
    }

    async function startRecognition() {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        alert("Tu navegador no soporta reconocimiento de voz.");
        return;
      }

      const recognition = new SpeechRecognition();
      recognition.lang = "es-ES";
      recognition.interimResults = false;
      recognition.start();

      responseBox.textContent = "üéß Escuchando...";

      recognition.onresult = async (event) => {
        const userText = event.results[0][0].transcript;
        responseBox.textContent = "üó£Ô∏è T√∫: " + userText;

        const reply = await getGPTReply(userText);
        responseBox.textContent += "\nü§ñ VisionDex: " + reply;

        await speakWithElevenLabs(reply);
      };

      recognition.onerror = (event) => {
        console.error("Speech recognition error:", event.error);
        responseBox.textContent = "‚ùå Error: no se pudo activar el micr√≥fono.";
      };
    }

    talkBtn.addEventListener("click", () => {
      startRecognition();
    });
  </script>
</body>
</html>
